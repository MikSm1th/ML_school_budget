{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's time to build a model\n",
    "- Always a good approach to start with a simple model\n",
    "- Gives us a sense of how challenging a problem is\n",
    "- Many more things can go wrong in complex models\n",
    "- How much signal can we pull out using basic methods?\n",
    "- Train basic model on numeric data only \n",
    " - We want to go from raw data to predictions quickly\n",
    "- Multi-class logistic regression\n",
    " - Train classifier on each label seperately and use those to predict\n",
    "- Format predictions and save to csv \n",
    "- Compute a log loss score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the multi-class dataset\n",
    "- Recall: Train-test split\n",
    " - Will not work here\n",
    " - If we split our dataset randomly, we may end up with labels in our test set that never appeared in our training set.\n",
    "- Solution: StratifiedShuffleSplit\n",
    " - Only works with a single target variable\n",
    " - We have many target variables\n",
    " - `multilabel_train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126071.000000</td>\n",
       "      <td>3.957220e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.426794</td>\n",
       "      <td>1.310586e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.573576</td>\n",
       "      <td>3.682254e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.087551</td>\n",
       "      <td>-8.746631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000792</td>\n",
       "      <td>7.379770e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.130927</td>\n",
       "      <td>4.612300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.652662e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.800000</td>\n",
       "      <td>1.297000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FTE         Total\n",
       "count  126071.000000  3.957220e+05\n",
       "mean        0.426794  1.310586e+04\n",
       "std         0.573576  3.682254e+05\n",
       "min        -0.087551 -8.746631e+07\n",
       "25%         0.000792  7.379770e+01\n",
       "50%         0.130927  4.612300e+02\n",
       "75%         1.000000  3.652662e+03\n",
       "max        46.800000  1.297000e+08"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('TrainingData.csv', index_col=0)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_train = df[NUMERIC_COLUMNS].fillna(-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_use = pd.get_dummies(df[LABELS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(\n",
    "                                                    data_to_train,\n",
    "                                                    labels_to_use,\n",
    "                                                    size=0.2, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneVsRestClassifier\n",
    " - Treats each column of y independently\n",
    " - Fits a seperate classifier for each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      320222 non-null float64\n",
      "Total    320222 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Data columns (total 2 columns):\n",
      "FTE      80055 non-null float64\n",
      "Total    80055 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 72072\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                    label_dummies,\n",
    "                                                    size=0.2, seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 23s, sys: 2 s, total: 8min 25s\n",
      "Wall time: 8min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "CPU times: user 1.31 s, sys: 72 ms, total: 1.39 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "holdout = pd.read_csv('TestData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50064 entries, 180042 to 249087\n",
      "Data columns (total 2 columns):\n",
      "FTE      50064 non-null float64\n",
      "Total    50064 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "holdout = holdout[NUMERIC_COLUMNS].fillna(-1000)\n",
    "holdout.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.58422797e-02, 6.46624377e-03, 8.29891300e-04, ...,\n",
       "        1.69612500e-01, 1.99296715e-02, 8.10543000e-01],\n",
       "       [3.58482728e-02, 6.46610320e-03, 8.29902557e-04, ...,\n",
       "        1.69607057e-01, 1.99300220e-02, 8.10552551e-01],\n",
       "       [1.20946821e-01, 9.06528221e-03, 1.53268023e-03, ...,\n",
       "        9.59263311e-02, 5.10388015e-02, 9.28396081e-01],\n",
       "       ...,\n",
       "       [1.22222570e-01, 9.05175340e-03, 1.53411191e-03, ...,\n",
       "        9.56957120e-02, 5.10986918e-02, 9.28680377e-01],\n",
       "       [1.22275131e-01, 9.04893421e-03, 1.53377914e-03, ...,\n",
       "        9.57019699e-02, 5.10808744e-02, 9.28670860e-01],\n",
       "       [1.22159718e-01, 9.05015147e-03, 1.53365017e-03, ...,\n",
       "        9.57227211e-02, 5.10754795e-02, 9.28645295e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict_proba(holdout)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If .predict() was used instead:\n",
    " - Output would be 0 or 1\n",
    " - Log loss penalizees being confident and wrong\n",
    " - Worse performance compared to .predict_proba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting your predictions as a csv\n",
    "- All formatting can be done with the pandas to_csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],\n",
    "                               prefix_sep='__',).columns,\n",
    "                               index=holdout.index,\n",
    "                               data=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function__Aides Compensation</th>\n",
       "      <th>Function__Career &amp; Academic Counseling</th>\n",
       "      <th>Function__Communications</th>\n",
       "      <th>Function__Curriculum Development</th>\n",
       "      <th>Function__Data Processing &amp; Information Services</th>\n",
       "      <th>Function__Development &amp; Fundraising</th>\n",
       "      <th>Function__Enrichment</th>\n",
       "      <th>Function__Extended Time &amp; Tutoring</th>\n",
       "      <th>Function__Facilities &amp; Maintenance</th>\n",
       "      <th>Function__Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type__Rent/Utilities</th>\n",
       "      <th>Object_Type__Substitute Compensation</th>\n",
       "      <th>Object_Type__Supplies/Materials</th>\n",
       "      <th>Object_Type__Travel &amp; Conferences</th>\n",
       "      <th>Pre_K__NO_LABEL</th>\n",
       "      <th>Pre_K__Non PreK</th>\n",
       "      <th>Pre_K__PreK</th>\n",
       "      <th>Operating_Status__Non-Operating</th>\n",
       "      <th>Operating_Status__Operating, Not PreK-12</th>\n",
       "      <th>Operating_Status__PreK-12 Operating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180042</th>\n",
       "      <td>0.035842</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.032077</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.052099</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>0.116126</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.831241</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>0.169612</td>\n",
       "      <td>0.019930</td>\n",
       "      <td>0.810543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28872</th>\n",
       "      <td>0.035848</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.023919</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.052102</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.116164</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.831233</td>\n",
       "      <td>0.141041</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.169607</td>\n",
       "      <td>0.019930</td>\n",
       "      <td>0.810553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186915</th>\n",
       "      <td>0.120947</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.043858</td>\n",
       "      <td>0.031715</td>\n",
       "      <td>0.113907</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.136221</td>\n",
       "      <td>0.135391</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.501655</td>\n",
       "      <td>0.472173</td>\n",
       "      <td>0.098601</td>\n",
       "      <td>0.095926</td>\n",
       "      <td>0.051039</td>\n",
       "      <td>0.928396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412396</th>\n",
       "      <td>0.120381</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.043808</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>0.113723</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.134056</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.502143</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>0.098399</td>\n",
       "      <td>0.096029</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.928269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427740</th>\n",
       "      <td>0.121725</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>0.043926</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.114158</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.137236</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.500987</td>\n",
       "      <td>0.473061</td>\n",
       "      <td>0.098879</td>\n",
       "      <td>0.095785</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>0.928570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Function__Aides Compensation  Function__Career & Academic Counseling  \\\n",
       "180042                      0.035842                                0.006466   \n",
       "28872                       0.035848                                0.006466   \n",
       "186915                      0.120947                                0.009065   \n",
       "412396                      0.120381                                0.009071   \n",
       "427740                      0.121725                                0.009057   \n",
       "\n",
       "        Function__Communications  Function__Curriculum Development  \\\n",
       "180042                  0.000830                          0.023918   \n",
       "28872                   0.000830                          0.023919   \n",
       "186915                  0.001533                          0.028599   \n",
       "412396                  0.001532                          0.028573   \n",
       "427740                  0.001534                          0.028634   \n",
       "\n",
       "        Function__Data Processing & Information Services  \\\n",
       "180042                                          0.008916   \n",
       "28872                                           0.008916   \n",
       "186915                                          0.016042   \n",
       "412396                                          0.016044   \n",
       "427740                                          0.016038   \n",
       "\n",
       "        Function__Development & Fundraising  Function__Enrichment  \\\n",
       "180042                             0.000173              0.032077   \n",
       "28872                              0.000173              0.032078   \n",
       "186915                             0.018150              0.043858   \n",
       "412396                             0.018120              0.043808   \n",
       "427740                             0.018190              0.043926   \n",
       "\n",
       "        Function__Extended Time & Tutoring  \\\n",
       "180042                            0.024406   \n",
       "28872                             0.024406   \n",
       "186915                            0.031715   \n",
       "412396                            0.031688   \n",
       "427740                            0.031752   \n",
       "\n",
       "        Function__Facilities & Maintenance  Function__Facilities Planning  \\\n",
       "180042                            0.052099                       0.000048   \n",
       "28872                             0.052102                       0.000048   \n",
       "186915                            0.113907                       0.017293   \n",
       "412396                            0.113723                       0.017261   \n",
       "427740                            0.114158                       0.017338   \n",
       "\n",
       "                       ...                   Object_Type__Rent/Utilities  \\\n",
       "180042                 ...                                      0.010729   \n",
       "28872                  ...                                      0.010728   \n",
       "186915                 ...                                      0.005622   \n",
       "412396                 ...                                      0.005630   \n",
       "427740                 ...                                      0.005612   \n",
       "\n",
       "        Object_Type__Substitute Compensation  Object_Type__Supplies/Materials  \\\n",
       "180042                              0.036846                         0.116126   \n",
       "28872                               0.036959                         0.116164   \n",
       "186915                              0.136221                         0.135391   \n",
       "412396                              0.125189                         0.134056   \n",
       "427740                              0.152629                         0.137236   \n",
       "\n",
       "        Object_Type__Travel & Conferences  Pre_K__NO_LABEL  Pre_K__Non PreK  \\\n",
       "180042                           0.017360         0.831241         0.141031   \n",
       "28872                            0.017361         0.831233         0.141041   \n",
       "186915                           0.016041         0.501655         0.472173   \n",
       "412396                           0.016029         0.502143         0.471525   \n",
       "427740                           0.016059         0.500987         0.473061   \n",
       "\n",
       "        Pre_K__PreK  Operating_Status__Non-Operating  \\\n",
       "180042     0.027749                         0.169612   \n",
       "28872      0.027751                         0.169607   \n",
       "186915     0.098601                         0.095926   \n",
       "412396     0.098399                         0.096029   \n",
       "427740     0.098879                         0.095785   \n",
       "\n",
       "        Operating_Status__Operating, Not PreK-12  \\\n",
       "180042                                  0.019930   \n",
       "28872                                   0.019930   \n",
       "186915                                  0.051039   \n",
       "412396                                  0.051012   \n",
       "427740                                  0.051075   \n",
       "\n",
       "        Operating_Status__PreK-12 Operating  \n",
       "180042                             0.810543  \n",
       "28872                              0.810553  \n",
       "186915                             0.928396  \n",
       "412396                             0.928269  \n",
       "427740                             0.928570  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A very brief introduction to NLP\n",
    "- Data for NLP:\n",
    " - Text, documents, speech...\n",
    "- Tokenization\n",
    " - Splitting a string into segments\n",
    " - Store segmments as list\n",
    "- Example: 'Natural Language Processing' \n",
    " - --> ['Natural', 'Language', 'Processing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens and token patterns\n",
    "- Tokenize on whitespace\n",
    " - **PETRO-VEND FUEL AND FLUIDS**\n",
    " - **PETRO-VEND | FUEL | AND | FLUIDS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words representation\n",
    "- Count the number of times a particualar token appears\n",
    "- \"Bag of words\"\n",
    "- This approach discards information about word order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing text numerically\n",
    "- Bag of words \n",
    " - Simple way to represent text in machine learning\n",
    " - Discards information about grammar and word order\n",
    " - Computes frequency of occurrence\n",
    "- CountVectorizer()\n",
    " - Tokenizes all the strings\n",
    " - Builds a 'vocabulary' \n",
    " - Counts the occurences of each token in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134338                      KINDERGARTEN\n",
       "206341     BUILDING IMPROVEMENT SERVICES\n",
       "326408             Instruction - Regular\n",
       "364634    GENERAL MIDDLE/JUNIOR HIGH SCH\n",
       "47683      GENERAL HIGH SCHOOL EDUCATION\n",
       "Name: Program_Description, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Program_Description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "df.Program_Description.fillna('', inplace=True)\n",
    "\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='\\\\S+(?=\\\\s+)', tokenizer=None,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_basic.fit(df.Program_Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'There are {} tokens in Program_Description if tokens are any non-whitespace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 434 tokens in Program_Description if tokens are any non-whitespace\n"
     ]
    }
   ],
   "source": [
    "print(msg.format(len(vec_basic.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4757 tokens in the dataset\n",
      "There are 3284 alpha-numeric tokens in the dataset\n",
      "CPU times: user 41.7 s, sys: 556 ms, total: 42.3 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
